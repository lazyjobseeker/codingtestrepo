{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.2, 1.268536259208993)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi8AAAGdCAYAAADaPpOnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABQpElEQVR4nO3de3yU5bnv/09mkskBkpAQknAIhAASDiGcFNFS9ddUrC7Xdm331lq6ZLHU2m61avauQlWobTXiUmtbrQraintJ1S6XbXexuCwtNbYoyEnCGQcIAjkZSEJCTjPz++POnJJJSCCTmcl836/XvJjnyfM8uTWQXLnv676uGJfL5UJEREQkQlhCPQARERGRvlDwIiIiIhFFwYuIiIhEFAUvIiIiElEUvIiIiEhEUfAiIiIiEUXBi4iIiEQUBS8iIiISUWJDPYD+5nQ6OXHiBMnJycTExIR6OCIiItILLpeLhoYGRo0ahcXS89zKoAteTpw4QU5OTqiHISIiIufh2LFjjBkzpsdrBl3wkpycDJj/+JSUlBCPRkRERHqjvr6enJwcz8/xngy64MW9VJSSkqLgRUREJML0JuVDCbsiIiISURS8iIiISERR8CIiIiIRRcGLiIiIRBQFLyIiIhJRFLyIiIhIRFHwIiIiIhFFwYuIiIhEFAUvIiIiElEUvIiIiEhECWrw8sEHH3D99dczatQoYmJi+O1vf9vj9f/5n//JV7/6VUaMGEFKSgrz58/nvffeC+YQRUREJMIENXhpbGyksLCQ559/vlfXf/DBB3z1q1/l3XffZevWrVx11VVcf/31bN++PZjDFBERkQgS43K5XAPyiWJieOedd7jhhhv6dN+0adO4+eabWb58ea+ur6+vJzU1lbq6OjVmFBERiRB9+fkd1l2lnU4nDQ0NpKend3tNS0sLLS0tnuP6+vqBGJqIiIiESFgn7D711FOcOXOGm266qdtrSkpKSE1N9bxycnIGcIQiIiIy0MI2eFm7di2PPvoob731FpmZmd1et2zZMurq6jyvY8eODeAoRUREZKCF5bLRG2+8we23385vfvMbioqKerw2Pj6e+Pj4ARqZiIiIhFrYzbz8+te/ZsmSJfz617/muuuuC/VwREREJMwEdeblzJkzHDp0yHN8+PBhduzYQXp6OmPHjmXZsmUcP36c1157DTBLRYsXL+anP/0p8+bNo6KiAoDExERSU1ODOVQRERGJEEGdefnkk0+YNWsWs2bNAqC4uJhZs2Z5tj2fPHmS8vJyz/WrVq2ivb2du+66i5EjR3pe9957bzCHKSIiIhFkwOq8DBTVeREREYk8ffn5HXY5LyIiIiI9UfAiIiIiEUXBi4iIiESUsKzzIiLi1tICjY3Q1ATNzdDWBq2t0N7uf11sLNhsEBcHiYmQlARDhphzIjK4KHgRkbBx9izU1sLp0+ZVX981SOmr+HhIS4NhwyA93by3aM5ZJKIpeBGRkHE4oLra+2ps7P/P0dICFRXmBWaGZsQIyM42r1h9FxSJOPpnKyIDyuGAqio4cQIqK81xdxITITnZLP8kJZnjuDizFBQbCzEx5jqXy8zQuJeUmppMINTYCHV15rxbezucPGleVqsJYHJyTEAjIpFBwYuIDIi6OjhyxAQtgZaCYmLMsk5GhlniGTasf/JVXC4TxJw6ZWZ3qqq8wYzDAcePm1dyMuTlwejRJqgRkfCl4EVEgsYdHBw5YoKXzmw2GDkSsrJg+PDgLOHExMDQoeaVk2OCmVOnvEGLO5BpaICdO2HfPpg0CcaNU26MSLhS8CIi/a6tzQQshw+bnBNfsbEwapR5ZWR4l34GinuGJz0dpk0zS1d2u0kUBjPesjL47DOYPBnGjBn4MYpIzxS8iEi/aW2FQ4fg6NGuS0OpqZCba4KWcEmStVjMzM/IkWZ306FDJhcGzM6nHTvMf8uMGaBuIyLhI0y+hYhIJGtrM7MXdrt/0BITYwKDCRNMDks4GzYM5s41y1v79pncGDBLTB98AOPHQ36+8mFEwoGCFxE5b06nWRo6eNB/R4/FAmPHmgTYIUNCN77zkZoK8+ZBTQ3s2gVnzpg8GbvdLDHNnh3+gZjIYKfgRUTOS2Ul7N7tX5slJsYkuk6aBAkJoRtbf8jIgCuuMLkvBw+a5OPGRvjwQ7joIvPfqFwYkdBQ8CIifdLYaBJa3csqbqNHmwTXSJtp6YnFYoKUkSNh+3aTF+Nywf79Zjlp9mxTd0ZEBpaCFxHpFafTzEAcOmTeuw0fDtOnD+6E1qFD4fLLzX//wYMmgKmqMrkwc+eapSYRGTgKXkTknE6dMjVQGhq85xISYOpUM+MSDSwWM7M0fDhs3eqt5PvhhzBnjqnUKyIDQyWYRKRbDofJa/nwQ2/gEhMDEyfCVVdFT+Diy50L407adTphyxaTuCwiA0MzLyIS0KlTsG2bmV1wS02FmTMH9xJRbyQkmGWkHTtMlV4weUBnz5rZKBEJLgUvIuLH5TJ5HQcOmPdglkzy883WZ+2wMSwWk7CblGT+f4HZmdTeDgUF+v8kEkwKXkTEo6nJ7Kpxl8oHSEuDWbMG1y6i/pSfb7pdf/qpOT561AR9M2YogBEJFgUvIgKY5Y9PP/VWyI2JUT2T3ho3zrQ82L7dBC7l5SYXZuZM/b8TCQYFLyJRzuk0SblHjnjPJSWZJZG0tJANK+KMHm0ClW3bTADz+eemlcCMGaEemcjgo+BFJIqdPQuffGKKr7mNGWNyNsKleWIkGTXK5MJ88okJYI4eBZvNLC2JSP/RVmmRKFVVBX/9qzdwsVigsNDktyhwOX/Z2eb/odvBg6Yvkoj0H32LEolCBw6YEvduSUlw8cXaAt1fRo82RezKyszx7t1me/WoUaEdl8hgoeBFJIo4HKY2yYkT3nPZ2SaxVD16+tf48abTtjtI3L7d7EpSHpHIhdOykUiUaG6Gv/3NP3DJzze9eRS4BMdFF8HYsea9uxLv2bOhHZPIYKDgRSQKnD4NpaVQV2eOY2Phkku0DXogFBSYfkgALS2webN3O7qInB8FLyKD3IkTZsaludkcJyXBl74EWVmhHVe0sFjM7Ja7yF99vbegnYicHwUvIoPYZ5+ZDshOpzkePhwWLIDk5NCOK9rYbGamy72L6/hxNXIUuRAKXkQGIZfL7HTZs8d7buxYuPRS84NUBt7QoSYx2m3PHtP8UkT6TsGLyCDjdJrZFt/f7CdPNjVcLPoXH1IjR8KECea9++vU2hraMYlEIn0rExlE2tpg0yY4edIcx8SY3/YvuiikwxIf+fmQnm7enz0LO3eGdjwikUjBi8gg0dwMH37o7QhttZo8i5yc0I5L/FksMGeOd/muosI0chSR3lPwIhKuNm6EO+4wf55DU5PZUXTmjDmOj4fLLoPMzKCOUM5TQoJZxnMrK4PGxtCNRyTSKHgRCTd2OyxdClddBS+/bP7sIYBpaDCBS1OTOXZvhR42bEBGK+cpOxvGjTPvHQ7Tjdq9K0xEeqbgRSSc2O2mqtnKlf7nX3894OV1dfD3v3truCQnw+WXmwBGwt+0ad76L6dPmyaOInJuCl5EwklpqXcKxdeiRV1O1daawMW9WyU11SwVJSQEeYzSb6xWmD3bW+X40CFTxE5EehbU4OWDDz7g+uuvZ9SoUcTExPDb3/72nPds3LiR2bNnEx8fz8SJE3n11VeDOUSR8LJgQddCLA89BFde6Xequho++shbZj493QQuquESeYYNg4kTzXun0+w+crlCOiSRsBfU4KWxsZHCwkKef/75Xl1/+PBhrrvuOq666ip27NjBfffdx+233857770XzGGKhI/y8q6FPx57zC/npbra9MdxOMxxZqYpPherHvER66KLTBE7MMtHqr4r0rOgfrv72te+xte+9rVeX//iiy8yfvx4nn76aQCmTJnChx9+yE9+8hMWLlwYrGGKhI8XXgh8/vXX4corPYGLO7EzO9tsu1XxuchmsZjdR3/7mznet8/0nnLnw4iIv7D6lrdp0yaKior8zi1cuJBNmzZ1e09LSwv19fV+L5GIZbUGPn/VVV0Cl5EjFbgMJunpMH68ee9wqHmjSE/C6tteRUUFWZ1a3WZlZVFfX8/Zs2cD3lNSUkJqaqrnlaOKXBKp7Hb4zW8Cfqj6C0uXwGX2bAUug01+PiQmmvc1NaYjuIh0FfHf+pYtW0ZdXZ3ndezYsVAPSaTv7HYoKfFm4PqoJoPNZ6YqcIkCsbEwfbr3ePfugH8lRKJeWKX4ZWdnU1lZ6XeusrKSlJQUEt2/jnQSHx9PfHz8QAxPJDjctV0CbJGuJoPNXIKzshqmK3CJBtnZJgm7qsrU7zl4EKZMCfWoRMJLWH0LnD9/Phs2bPA79/777zN//vwQjUgkCOx2WLPG/LlxI9xyS8DApZY0tnAxTqwwbZoClygyfbr362y3e9s+iIgR1JmXM2fOcOjQIc/x4cOH2bFjB+np6YwdO5Zly5Zx/PhxXnvtNQC+/e1v89xzz/HAAw/wr//6r/z5z3/mrbfeYt26dcEcpsjA8Z1lsdm6bovuUEcKHzMPB1bARXbFDmbPvkaBS5QYMgQmTDCzLk6n6X106aWhHpVI+Ajqt8JPPvmEWbNmMWvWLACKi4uZNWsWy5cvB+DkyZOU+7RTHT9+POvWreP999+nsLCQp59+mpdfflnbpCXy2e3wb/8Gy5Z5Z1m6CVwaGMpHXEp7x+8WI6hmzm+WKnCJMpMmeZN3q6vNMpKIGDEu1+Cq5VhfX09qaip1dXWkpKSEejgiJnCZNs3bgKgHjSTxdy6jGVPjP51aLuUjrIUFsGNHkAcq4ebECdi61bxPToYrrvC2EhAZbPry81u/y4kEW2lprwKXsySwifmewCWVOi5hM1bUajhajRoFaWnmfUMDaDOliKHgRSTYxo075yUt2NjEfM5i1gmSaeBSPiKOjn2yLS3BHKGEsalTve/37/e2hRCJZgpeRILt6NEeP9yOlY+ZRyOmFvwQGrmUj7DR5r3oiiuCOUIJY+npZvs0mAm8zz4L7XhEwoGCF5FgGzcO4uICfshJDFu4mDpSAUigmflsIoFOMy1f/3qwRylhbOpUb67LoUOaiBNR8CISTHY7XHcdtLV1+ZAL2M4sasgAII425rOJRALkx5xj9kYGtyFDIDfXvHc4TAAjEs0UvIj0N98idKWlAQvQAexhKicYBYAVB/P4mKE0Bn5mL/JmZHCbNMnbt/PIkV7lgIsMWgpeRPqTuwjdv/yL6bK3aZO3WIePQ0zATh4AMbiYw1bSON39czXzEvXi471dp51OU8BOJFopeBHpT74zLW1t8NJLXRIUjjGGvXib1RSykyx6qEBms8GCBcEYrUSYCRNM80aA8nI4eza04xEJFQUvIv0p0PKO01unpYoR7KTQc5zPPnL4vOdn/upXkJfXXyOUCGaz+c++HDgQ2vGIhIqCF5H+1MPyTh0pfMJcXJhtI+M5zCR6kXkZINlXoteECd7Na8eOQWM3aVIig5mCF5H+NG6c+fW4k7Mk+DRahFGcYBq7z/28pCQtGYmfuDjvRJzLpZ1HEp0UvIj0B7sdli6Fq6/u0nCxjVg+Zh4txAOmX9EsttNjixqbDZ58Enbt0pKRdJGX5519+fxz5b5I9IkN9QBEIprdDqtWwdNPQ3t7lw87iWErc2ggGTDVcy9mCxZ66Id6553wwAMKWqRbsbGm7svBgyb3xd37UyRaaOZF5Hy5f2KsXBkwcAHYRQHVjADARivz+Ni/7H8gL71ktpKI9CAvz1v35ejRLhN+IoOagheR83WObtGHmEA5YwGw4ORitjCEwAXrunj99f4YoQxiNpt3c5vDYWJpkWih4EXkfNjtUFUVMDkX4AQj/Wq5zGI76Zzq/fMXLbrQEUoUyMsDS8d38SNHup0AFBl0lPMi0lfuKrpNTd6fHD5qSWM7szzH+exjFCd7fmZSEqxeDX/5iwlcrryynwctg1FiIowZY1YZ29pMADNxYqhHJRJ8Cl5E+sq3iq5PATqAJhLZwsU4OyY1x1Lecy0XiwWeeAJuvNH8Gv2NbwRr1DJITZzoTZE6fNh/NkZksNJfcZG+cC8XBehX1I6VzVxCK2YpaQTVFLCr5+dZLN7AReQ8DBkC2dnmfXMznDgR2vGIDAQFLyK95d5d9MADZo7eXacdcAHbmeXZEj2UM8xha89bosEkKbz9dhAHLdFgwgTveyXuSjRQ8CJyLnY7rFljisa5dxe1t5s5+g77mUwF5tffONq4hM3E0cvsyRUr9BNHLkh6OqSmmvd1dfDFF6Edj0iwKedFpCe+ybkxgWviHmcUB5kEQAwu5rD13FuirVazvxVMedTSUi0dyQWZMAG2bTPv7XYYPjy04xEJJs28iATinm15+21vcq6r6xLQaVLZwUzP8TR2M4Kars8bORIeeshbVSw21ps3o/5F0g9GjoSEBPO+okING2Vw08yLSGcbN8LChaZkaUICxMdDS0uXy5qJZzOXeHYWjeMo4zkS+Jk1NWZe3z3b0tJilqEyM03golkXuUAWi0nD2rvXHB8+DNOnh3ZMIsGimRcRX3a7N3ABk+Myc2aXyxxY2MwlnmaLw/mC6ZR1/9y2jpYASUneP2+8ERYvVuAi/WbcOO/knrv2i8hgpOBFxFdpqX+TGKsVPv64y2U7KaQOkyGZRBNz+STwziJ3wQ13sLJrF7z6qrpFS1DExZmidWAm+Y4fD+14RIJFy0YivhYsMIGGu3puZiac9K+Oe4gJHGc0ALG0cwmbu2+2+H//r/n113dpSEGLBFFurmnUCKbibm5uCAcjEiSaeRHxlZcH69aZX2Gdzi6BSzUZ7CPfczyL7SRzpvvnjRqlpSEZUCkpZus0QEODtk3L4KTgRaKbe1eRu86K3W46OgdIFmgika3MwYXZMj2Z/WRT2fPzX3ihv0csck6+sy3uWRiRwUTLRhK9fGu4JCWZGZfrrvNujfbhwMIWLqaNOACyqGQSB8/9OXyq8IoMlJEjTcPz1lYzedjSYjbNiQwWmnmR6OXbYLGpycy4BAhcwCTo1pMCwBAamcV2Apes82Gzwbe+1X/jFekliwXGjjXvnU5v40aRwULBi0Qvd3IumD8XLTK5Lp3YGe+XoHsxWwKX/s/I8D/+8Y+V6yIhM26c9/3RowFrLIpELAUvEr3y8syW5SefhHvugS1b4Jpr/C6pYTh7mOo5nsmO7hN0f/rTrnVcREIkKclslgPTgaKqKrTjEelPynkReeSRgBV0z5Lgl6A7iYOMpCLwMywWuPRSEwyVlqpqroSF3Fxv0FJeDllZIR2OSL/RzItEt7ffDhi4uBN0W7EBMIJqJrO/++c4neZZeXnaGi1hIzPT2++osjLgX3WRiKTgRaKP7/bobopg7KLAr4LuHLaeO0FXJMzExHgr7rpc8PnnoR2PSH/RspFEF9/t0XFx3kaJPsrJ4Rg5AFhxdJ+g68tqVY6LhKWxY+HQIfP+2DGYMCG04xHpD5p5kehht0NJiXc7dFubWe7xUU8yuyjwHBeykxQazv3s117TUpGEpSFD/CvunjoV2vGI9AfNvEh08J1x6UYbsXzCXJwdMX0uRxjNiZ6f++Uvw6OPwpVX9uNgRfrX2LFQW2veHzsGaWmhHY/IhQr6zMvzzz9Pbm4uCQkJzJs3j82bN/d4/bPPPsvkyZNJTEwkJyeH+++/n+bm5mAPUwY734J0YJIBOtnBTBoZAsAwTjON3T0/MykJfvUrBS4S9kaOhNiOX1WPHw+4WioSUYIavLz55psUFxezYsUKtm3bRmFhIQsXLqSqm4IDa9euZenSpaxYsYK9e/fyyiuv8Oabb/L9738/mMOUaDBunKl4C2Zbc6eKXZ+RRwXZAMTRxhy2YqGHql4PPmi2RWupSCJAbKzpEQrQ3t6l36hIxAlq8PLMM89wxx13sGTJEqZOncqLL75IUlISv/zlLwNe//e//53LL7+cb3zjG+Tm5nL11Vdzyy23nHO2RqRHdrvpWdTaao475bnUksZepniOZ7GdJM72/MwpUxS4SETJyfG+V7sAiXRBC15aW1vZunUrRUVF3k9msVBUVMSmTZsC3nPZZZexdetWT7Bit9t59913ufbaa4M1TBnsOifpdtKCrUshuizOUYo0MdEUoROJIOnpJnkXTIWAs+eIz0XCWdASdmtqanA4HGR1KumYlZXFvn37At7zjW98g5qaGr70pS/hcrlob2/n29/+do/LRi0tLbT4VF6qr6/vn/8AiWx2uykat2JFt9+lXcA2ZtOMqeKVQU3PhejcHn1Usy4SkcaMgf0df8WPH4eJE0M7HpHzFVZbpTdu3Mjjjz/OL37xC7Zt28Z//ud/sm7dOn70ox91e09JSQmpqameV47v3KhEJ/fOogce6PHXy/1MpgbTTDGBZmaz7dyF6NSzSCLY6NHe98ePh24cIhcqaMFLRkYGVquVyspKv/OVlZVkZ2cHvOeRRx7hn//5n7n99tspKCjgn/7pn3j88ccpKSnB2SlPwW3ZsmXU1dV5XseOHev3/xaJMJ13FgVQxQgOMgmAGFzMZhvxtHZ/Q0KCaeCoJF2JYEOGeLdJ19ebl0gkClrwYrPZmDNnDhs2bPCcczqdbNiwgfnz5we8p6mpCYvFf0hWqxUAVzf93OPj40lJSfF7SZRbsMDkpQDEx/tnKmIaLm5jtud4CnsZTm33z7v9dti9G773PQUuEvHc7QJAsy8SuYK6bFRcXMzq1atZs2YNe/fu5Tvf+Q6NjY0sWbIEgFtvvZVly5Z5rr/++ut54YUXeOONNzh8+DDvv/8+jzzyCNdff70niBHpFXchi7Y2v+/Q7jyXNuIAyKaCCdi7f05iIixbpqBFBo1Ro7xljj7/vEvVAJGIENQKuzfffDPV1dUsX76ciooKZs6cyfr16z1JvOXl5X4zLQ8//DAxMTE8/PDDHD9+nBEjRnD99dfz2GOPBXOYMljY7WbJaO/ebrdF72cytZha6YmcZSY7en6mknNlkLHZTLfpykpobjaVd4cPD/WoRPomxtXdekyEqq+vJzU1lbq6Oi0hRRPf8v9Wa8ASotVk8BGXAibP5XL+Rhqnu39mYiKUlSl4kUHn+HHYts28HzsWCgtDOx4R6NvP77DabSRy3nyTdAMELi3Y2M4sz3E++3oOXAC++10FLjIoZWd72wWcPNllglIk7Cl4kcFhwQKzjRkgLs6vd5E7z6WFeAAyqWICn3V9xoQJ/seaS5dBymo1AQyYtLBuOraIhC0FLxL53Lku69bBnXea78Y+q6GHmOhXz2UW2wPXczl+3OxOArM1WvVcZBBz9zoCOHGO5uki4SaoCbsiQeeb62KzeRN1O9SSxn4mA956LjbaAj+rudnUcsnMNDM5WjKSQWzECDNJ2dZmknedTtOzVCQSKHiRyPb2295cl06BSytxXfoW9VjPJTHRzLYoaJEoYLGYpaNjx0yn6aoq71KSSLhTnC2Rw26HNWvMn+7jhx/u9vIdzPT0LRrOF1zEgZ6frwRdiTJaOpJIpZkXiQy+y0NJSaZM/9tvd5lt8VzOeCox9YRstPaub9HPfgbXXANHj2rZSKJCRob/0pHDYZJ5RcKdgheJDL5boZuaoKSk2++yp0llL1M8x7PYTgItAa/1c/YsLFxoAiJ3gKQARgaxzktH1dVaOpLIoGUjiQy+W6EBXn7ZvDppx8o2ZuPs+Ks9gc/IpLrr8+JMewASErx9kHwTfpuaTMAkMshp6UgikYIXiQx5eWYm5PbbvecCFKMrYzqNDAFgGKfJZ1/XZ1mtZlfRq6+ahotlZeb9e+95A6SkJBMwiQxy7qUjgIqKgP+sRMKO2gNIZLHbYdo0s625k+OM8nSLjqWdL/MBQ2jq/ll/+QtceWXX55eWKudFosrOnVBebt7PnQsjR4Z2PBKd1B5ABrd//Mcup5pIZBcFnuMCdvUcuAC8/nrXc3l5sHixAheJKr7BSkVF6MYh0ltK2JXI4bvjyIcL2M4s2jBz36M5zhiOn/t5ixYFYZAikScjw/Q6am9XwTqJDApeJHL47jjycZBJ1JIOQBJNFLAr8P2JiSbJ93e/g/HjTTtdEcFigaws0yGjrQ2++MJU4BUJV4qtJbz5FqZbsMDbe6hDLWkc4CLAlP+fxXbiaO/6nFtuMYm5l14Kf/gDrFxpZnHcBe9EopzvFmktHUm408yLhC/fZaKYGJg8GVq89VraiGU7szzl/y/iAOmcCvyshQtNHsuaNf71YkpLld8igmnpZbGYJaOKCvNPTyRcaeZFwpfvMpHLBfv8tz3vooAmzNbmdGqZxMHAz4mL82579q0Xo+3QIh6xsSb3BcxmvtOnQzockR4peJHwtWBBt1V0P2c0xxkNmG3Rs9geuPx/XBz81395Z1fc9WJefVUVdEU60dKRRAoFLxJ+3Hku4F+UrkMjSX7bomfwKUmc7fqca681szWda7loO7RIQApeJFIo50XCS+cGjOvWwSuvmD2cgJMYtjOL9o6/ujkcYzTd1DRftEgBikgfxMdDejrU1kJDAzQ2wpAhoR6VSFeaeZHw0rkB45YtcNttJmEXOMBFnCINgCE0Mp2y7p/1l78Ee7Qig45mXyQSaOZFwos7obapyTRNfOQRzw6jWtI4xETAbIuezTZi6aERi4rQifRZdjbs2WPenzwJEyaEdjwigWjmRcKHu6/Q6tUm12XxYk/g0o7Vb1v0ZPYzjLrAz5kxI3DfIhE5pyFDIDnZvD91yttoXSScaOZFwsPGjaYWSzffKXczzW9b9EQOBX5OYiK8845yXUQuQFaWyXkBqKqCMWNCOx6RzjTzIqFnt/cYuFSQRTmmlH8s7cxkR+Bt0WAqbInIBcnM9L6vrAzdOES6o+BFQq+0tNvApQUbOyn0HE9jd8/doltazPNE5Lylp5sSSQDV1aZGpEg4UfAioedb9baTnRTSig2AbCoYy7Gen5WYqKq5IhcoJsbbmLGtzWydFgknCl4kPNxzj2c7tFs5OVSSBUA8Lczg056fcdNNpvmi8l1ELlhWlvd9VVXoxiESiIIXCS13UbqVK/3mphtJoozpnuNCdhKPz9LShAnw4INmpgXMzE1JiQIXkX6ivBcJZwpeJLR8i9J1cAHbmYUD09doLOVk0elXv88+M1uiy8rUp0gkCGw2SDP1IGlogLMBOnCIhIqCFwmtAPkuh5joV0V3GrsD3/vSS+pTJBJEvktHmn2RcKLgRQaeu/Gi3W6CjtWrzdIRcJpU9jMZMFV0Z7G9+yq6d945UCMWiUpaOpJwpSJ1MrA6N15cvdpTxt+Bxa+K7kQOkcbpwM+55Ra49NIBGrRIdEpNNV06mpuhpgYcDrBaQz0qEc28yEDr3Hhx5UrPh/YyhTMMBSCVOi7iQPfP+fWvTRBktwdztCJRzz374nSaAEYkHCh4kYE1bpy3+hWYRFugmgwOMx4AKw5msw0L56iM1dSkgnQiQeab91JdHbpxiPhS8CIDx26H664zVa/cXC7aiGUHMz2nprKHoTR2/xx38JOUpIJ0IkE2fLi3BJOCFwkXynmRgRNgWzRAGdNpJgGAEVSTy9Hun2GzwXvvwdGjJnDRLiORoIqLM1uma2vhzBmzZdpdXkkkVBS8yMBxb4v2CWAqyOJzTMvaONqYyY7u77daTeBy5ZXBHaeI+BkxwtsioLoaxo4N7XhEtGwkweW7LRpMG4B58wBoJc6v6eJ0ykigpftnvfaaAheREHD3OQK1CpDwoJkXCR7fbdEJCab8f4s3OPmUGX5NF8dwvOfn+ebKiMiAGTbMLB+1tZkdRy5Xl1ZkIgMq6DMvzz//PLm5uSQkJDBv3jw2b97c4/WnT5/mrrvuYuTIkcTHx3PRRRfx7rvvBnuYEgy+OS7NzX6By3FGcZKRANhoPXfTRZtNybkiIdK5y/Tp0yEdjkhwg5c333yT4uJiVqxYwbZt2ygsLGThwoVUdTPv2Nrayle/+lWOHDnCf/zHf7B//35Wr17N6NGjgzlMCZYApf8BmolnFwWe4wJ2+Tdd7Myd66LkXJGQ8V060q4jCbWgBi/PPPMMd9xxB0uWLGHq1Km8+OKLJCUl8ctf/jLg9b/85S+pra3lt7/9LZdffjm5ublcccUVFBYWBrxeIsA998DIkX6nPmUGbZjtzqM75mC6iI83f9ps8Kc/KddFJMQUvEg4CVrw0traytatWykqKvJ+MouFoqIiNm3aFPCe3//+98yfP5+77rqLrKwspk+fzuOPP47D0U1vG6ClpYX6+nq/l4QBux2mTTMVdE96g5NycqjEVL2Kp4XplAW+/7774PbbtbtIJEwkJsJQUwCbU6eUgiahFbTgpaamBofDQZZveUYgKyuLioqKgPfY7Xb+4z/+A4fDwbvvvssjjzzC008/zY9//ONuP09JSQmpqameV05OTr/+d8h5evttk+fi4ywJ7Gaa57iQndgI8B0wNhZ+9jN4+WVT1E4tAETCgnv2xeWCL74I7VgkuoXVVmmn00lmZiarVq1izpw53HzzzTz00EO8+OKL3d6zbNky6urqPK9jx44N4IilC7sd/u3f4JFH/E67gB3MpL1jg1sOx8jCJ/fJ3e3NaoXbbjOVsEAtAETCiJaOJFwEbat0RkYGVquVyk591CsrK8nOzg54z8iRI4mLi8Pq07Z0ypQpVFRU0Nrais1m63JPfHw88e78CAkt363RnRxlHDVkAJDIWaax2/8CV0cfI6sVXn3Vez4xUbuMRMLE8OFgsZgmjQpeJJSCNvNis9mYM2cOGzZs8JxzOp1s2LCB+fPnB7zn8ssv59ChQzidTs+5AwcOMHLkyICBi4SZVasCBi6NJLGHqZ7jQnYSR7v/Re6veWur35ZqHn1Uu4xEwkRsrGkVANDY6J0gFRloQV02Ki4uZvXq1axZs4a9e/fyne98h8bGRpYsWQLArbfeyrJlyzzXf+c736G2tpZ7772XAwcOsG7dOh5//HHuuuuuYA5T+sPGjSY5txP3cpEDM5uWyxFGUNP1fnezxYQEb+OUpCS48cbgjFdEzktGhvd9TYB/yiIDIagVdm+++Waqq6tZvnw5FRUVzJw5k/Xr13uSeMvLy7FYvPFTTk4O7733Hvfffz8zZsxg9OjR3HvvvTz44IPBHKb0hxdeCHjaTh61pAOQRBNT2Nv1IvdSUVubd4motFSNF0XCUEYG7N9v3tfUgPZISCjEuFzuZIPBob6+ntTUVOrq6khJSQn1cAY/u93sLHr4YbPk4+MMQ/grV+DsmOC7jL8znNrAz0lKgl27FKyIhDmnE9avB4fDTJR+9auhHpEMFn35+a3eRnL+ekjQdS8XuQOXPOzdBy7g3VWk4EUkrFkskJ5uEnabm03uy5AhoR6VRJuw2iotEca3d5Fbx04xO3mcwmT2DaGRfPb1/Cz1LhKJGMp7kVBT8CLnb9w4/+OcHHA6OcMQ9pHvOT2THVhx0i2bTb2LRCKIghcJNQUvcv6OHvU/PnYMl8vFTgr9lovSOeV/ne/OoiefhL171QJAJIKkpppt06DgRUJDOS/SN3a7dyfQuHHeilUdDjPes7uo2+WimBgTtNx4o2ZbRCJQTIwpWFdZafL0GxogOTnUo5JoouBFes83QTchwQQtPoFLI0l+y0WF7Ay8XNTaCpmZClxEIlhGhglewMy+KHiRgaRlI+m9t9/2Jug2N/ttjXYBOyn0FKMbz+Hudxep5L9IxFPei4SSghfpHbsdli/v9sNHyOULhgOmGF23u4sefBDKyjTrIhLhkpNNrj2YDtODq2KYhDsFL9I7paVmtiWAJhLZyxTPcSE7icXR9cJbboEnnlDgIjIIuPNewBTHrqsL7Xgkuih4kd5ZsMBUwe2k83LROI6SwReBnzFrVhAHKCIDzXfpqLaHGpQi/U3Bi/ROXp4p3//kk965YqCcsdRgvoMlcpap7Al8f0KCmiyKDDLumRcwS0ciA0XBi/ReXp5fAHKWBPYw1XMccLnIXctl925zvGaNyZ8RkYg3dKi3bJPyXmQgaau09M3bb3t2Ge2kkPaOv0JjKWcEnbYcWK3wxz+aAnS+26zVhFFkUHDnvVRUmLyXM2e0ZVoGhoIXOTe7HVatgo8/hr/+FYBycqhmBAAJNAdeLnI4vFV4ffsgqQmjyKCRnm6CFzCzLwpeZCAoeJGe2e0wZYpfTZdm4tnNNM9xITuJo73rvb71XNwJv+6ZF9V5ERkUfPNeamshNzdkQ5EoopwX6dmqVX6BC/gvF+VwjEyqu97XuZ6LO+H31Ve1ZCQyiKSmeprJK2lXBoxmXqR7GzfCypV+p44xhioyAbNcNI3dge+dMqVrgJKXp6BFZJCJiTFLR9XVphSUe3JVJJg08yLde/11v8POy0Uz+NR/ucjS8dfJZjNNG0UkKmjLtAw0BS/Svauu8jssYzptmH2RY/icLKr8r4+NNfsmW1vhuuu0JVokSqSne98reJGBoOBFvOx2/zosbW2eD50km5OMBMBGa+DlotZW7z3uHUUiMuilpXknXlVpVwaCcl7E6FyHZfVqk1wLtBHLLgo8lxawCxttgZ+TkGAWvrWjSCRqWCwwbJgJXBobzbeAhIRQj0oGMwUvYnSuw7JokedDu5lGC/EAZFPBKE52/5wf/hAyM03gouRckagxfLh31qW2FkaNCu14ZHBT8CKGbx0Wq9UUmAOqyeAYOQDE0k4Bu7p/RmKiaR+goEUk6gwfDgcPmvdffKHgRYJLOS9i+NZhuf12ABxY+JQZnkumsocEWgLfHxcH776rwEUkSqWlmW3ToLwXCT4FL+KVlweLF8PXvw7APvJpwhRsGM4XjKW8+3vb2rytAEQk6sTGQkqKeV9fD+0Bim6L9BcFL+LPbodHH+UUw7BjZlEsOClkJzGBrneX1lSCrkjUS0vzvj91KnTjkMFPOS/RbuNGU4zOnaBbVITT4WQnX/ZcMpn9DKEp8P2vvWZmXZSgKxL10tPhyBHz/tQpGDEipMORQUzBSzTbuNFbiO7ll82CtcvFISbRgGkNm0odE/is670xMfDv/w7f+MbAjVdEwprvzIvyXiSYtGwUrex2WLHC/5zLRQNDOcgkAGJwMZMdgZeLHnhAgYuI+ElK8tZ3OXUKXK7QjkcGL828RCPfgnQ+XJiO0c6OmHYih0ihoev9CQnwrW8NwEBFJNKkpcHJkyZht6HBm8Qr0p808xKNfAvS+TjMeE5h5n2HcoaLOBD4/h/+UPktIhKQb58jJe1KsCh4iUbugnTgaUjSRCL7yPdcUshOLASY83UXohMRCUB5LzIQFLxEo7w8WLcOrr0WnE4APmUGDsy251yOkE43vzI9+qhmXUSkW6mp3iaNmnmRYFHOS7Sx22HVKnjmGU8H6GOMoRqzpzGRs0xhb+B7k5I06yIiPercpLGlBeLjQz0qGWw08xJNNm6E/HxYudITuLRgYzfTPJfM4FNicXS998EHTfsAzbqIyDmoWJ0Em4KXaGC3w7/9G1x9tSdocdtFAW3EATCa42RSHfgZw4crcBGRXlHSrgSblo0Gu262RQNUkMVJRgJgo5XplA306ERkEFLSrgSbZl4Gu262RbcRyy4KPMfTKcNGW5frAFPXRbkuItJL8fHeDY2nT3v2BYj0GwUvg924cQFP7yOfZkwpzEyqGM2JwPfHxcEf/6glIxHpE/fSkdMJdXWhHYsMPgMSvDz//PPk5uaSkJDAvHnz2Lx5c6/ue+ONN4iJieGGG24I7gAHs6NHu5yqJY0j5AJgxcEMPu3+/ra2gM8QEemJ79LR6dMhG4YMUkEPXt58802Ki4tZsWIF27Zto7CwkIULF1JVVdXjfUeOHOH//J//w4IFC4I9xMFtwQJTWK6Dkxg+ZYbnOJ99JNLc/f02m3mGiEgfaMeRBFPQg5dnnnmGO+64gyVLljB16lRefPFFkpKS+OUvf9ntPQ6Hg0WLFvHoo4+Sp+WKC1Ne7rfD6DMmeDpGD+M04znc/b02G7z3npaMRKTPkpO9xeo08yL9LajBS2trK1u3bqWoqMj7CS0WioqK2LRpU7f3/fCHPyQzM5PbbrvtnJ+jpaWF+vp6v5d0sNvN9uj2dgDOMIQDXASYjtEz+DRwx2iAL38Z9u6FK68ckKGKyOBisZhqu2CK1bV1sx9A5HwENXipqanB4XCQlZXldz4rK4uKioqA93z44Ye88sorrF69ulefo6SkhNTUVM8rJyfngsc9KNjtcM89ft8xPmWGp2N0HnZS6SHQUxsAEblAynuRYAmr3UYNDQ388z//M6tXryYjI6NX9yxbtoy6ujrP69ixY0EeZQSw22H6dHj3Xc+pcnL4guEAJNHEZPYHvtdqhddf14yLiFywYcO875X3Iv0pqEXqMjIysFqtVFZW+p2vrKwkOzu7y/WfffYZR44c4frrr/ecc3YUCIiNjWX//v1MmDDB7574+Hji1TjD2LjRBB5WK5w96zndgo09TPUcz+BTrAQovHDTTVBSohkXEekXvsGLZl6kPwU1eLHZbMyZM4cNGzZ4tjs7nU42bNjA3Xff3eX6/Px8du3a5Xfu4YcfpqGhgZ/+9KdaEurJxo1w1VUBP7SbaZ4WAGP4nBHUdL0oMVGBi4j0qyFDTKmotjbNvEj/Cnp7gOLiYhYvXszcuXO55JJLePbZZ2lsbGTJkiUA3HrrrYwePZqSkhISEhKYPn263/3DOkL3zuelkxdeCHi6ihEcZzQAcbQxjd3+F9x5J8yfb7ZDK3ARkX6WlgZVVdDaaop9uyvvilyIoAcvN998M9XV1SxfvpyKigpmzpzJ+vXrPUm85eXlWCxhlXoTmcaP73LKgcWvpss0dndtATBhAixeHOzRiUiUGjbMBC9glo4UvEh/iHG5XK5QD6I/1dfXk5qaSl1dHSkpKaEezsCx22HyZM+2aIA9TOEzTI5QBjXM5yP/e+LiYN8+zbiISNBUVcHHH5v3eXkwbVpoxyPhqy8/vzXlMVjk5cGaNRBjKrfUkYIdE5RYcHpbAFit5k+bDf7rvxS4iEhQKWlXgkHBy2CxcSMsWQIuFy5gJ4W4OkrQXcQBhtDRWdrhgNhYuP9+GDs2ZMMVkehgs3mXiurq1GFa+oeCl8Fg7Vr4yldMRhxwmPHUYUpbJtPABD7zv769HVauhIICs9wkIhJE7mJ1DgecORPascjgoOAlktnt8O1vw6JFnl9nmkhkH/meSwrZiYVu0pqamqC0dCBGKiJRTMXqpL8FfbeRBIndbjLfmv07Qu+iAAcmr2U8h0njdNd73YUXkpLUMVpEgq5z3su4caEaiQwWCl4iVWlpl8DlOKOoIhOABJrJZ1/X+xITTduAo0dV20VEBkRqqtlL4HJp5kX6h4KXSLVgAcTHQ0sLAG3EUoa3kF8Bu4jF4X/PnXfCAw8oYBGRAWW1QnIy1NebnBeHw7vxUeR8KHiJVOXl5jtAhz1MpRUbACM5STb+/aS48kp48cUBHKCIiNewYSZ4cbnMn74dp0X6Sgm7kchuh4ULPQXpviCdcsy251jamU5Z13smTx7IEYqI+ElN9b5XvRe5UApeIlFpqWdbtJMYvxYAU9hLAi1d7+nUjVtEZCD5Bi91daEbhwwOCl4i0YIF0NEP6hATOcNQANI4xTiOdr0+Ph5uvHEgRygi4iclxVMAXMGLXDAFL5Fm40b47/8dnE4aSeIgkwCIwcUMPu2oqdvJj36kJF0RCSl30i5AQ4Nfyp5Inyl4iSRr18JVV8HOnYCp6eLs+BLmYSeFhq73JCVp1kVEwoJ76cidtCtyvhS8RAq7HW691XN4nFFUMwKARM4ymf1d77npJti1S7MuIhIWfIvVaelILoSCl0jx9tueedY2YtmNt698Abuw0qnbWWIilJQocBGRsKEdR9JfFLxEoL1MoYV4wNR0yaLK/4Lbb4eyMgUuIhJWlLQr/UXBS6S4+GIATjGMo5jGIAFrusTFwbJlClxEJOwoaVf6iyrshiu73SwVgUm4Xb++S02Xyez3r+litcKrrypwEZGwlZqqSrty4RS8hBt30PLII56+RTz0ELS1cZg86kkBIJU6xnPYe19srKm4e8cdcOmlCmBEJCwNGwbHjpn3dXUKXuT8KHgJJ3Y7TJvWpVs0bW2cJYH9mBL/AWu6dLQKoKnJVOBV8CIiYUiVdqU/KOclnLz9dtfApcMuCnBg2rDmcoRhdPOvPinJVOAVEQlDvkm72nEk50vBS7iw2+GTT/zPjR8P0NEjOguABJrJZ1/gZ+Tnq66LiIS1zkm7TmfP14sEomWjcNDdctHhw7RjpYzpnlPTKSOWblL08/IUuIhI2OuctOtbvE6kNzTzEg46LxfFeLNZ9jOZZhIAyKSKkVR0/5zvfS9YIxQR6TfKe5ELpZmXUAu0XORyAVBHCocxS0dWHBSwq+v9t9wCQ4bAokVw5ZVBHqyIyIVT8CIXSsFLKNntUFBgdgi5WSzgdOICPmUGro49RRdxgCTOdn3GrFmacRGRiJKS4n2vBo1yPrRsFEqlpf6Bi9XqyV47Qi6nGQZAMg3kYQ/8jC++MEGQiEiEiI01GyPBm/si0hcKXkLFboeqKtNAEUxZ/45a2c3Es498z6Uz+BQL3fzrXrnSzN4ogBGRCOJeOnI4oLExtGORyKNlo1DwXS5KSIAnnzQzKCtXAlDGdNo7vjRjKSedU957Y2PNyzfBV4XpRCTCpKTAyZPmfX09DB0a2vFIZNHMSyj4Lhc1N0NmJlxzDcTFUUkmJxkJgI1WprLHXJeTY2Zn3JV0H3zQO2ujwnQiEmGUtCsXQjMvobBggQk4mprMn+PGwbXX4mhzsIsCz2XT2E0cHcHKiRPeFqzNzTBlCpSVmUBowQLNuohIRFHSrlwIBS+hkJcH69bB66+bLc7r18PZsxwgn7OY2ZQMahjDce89DgfYbNDa6p1pUVE6EYlQiYlmMrmtTcGL9J2Cl1Cw2+G668zMy2uvQVsb9STzGRMAsOBkBp/635OQAH/8Ixw9qpkWERkUUlOhpsZMJre0QHx8qEckkULBSyj45ry0tuLCNF5013SZxEGG0OR/zz/+o4rQicigkpJighcwsy8jRoR2PBI5lLAbCuPGmSWgDsfIoZZ0AIbQyEQOdb3nv/23gRqdiMiAUNKunC8FLwNt40ZYuNDkrgCtxLGXKZ4PF7ArcE2XO+5QLRcRGVSUtCvnS8HLQLLb4eqrPYELwF6m0IqZhRnNcUZQE/hedy0XEZFBYuhQ0xEFNPMifaPgZSCtWmVS6zucYhjljAUglnZT08VnOYnYWJOoC6rlIiKDjsUCycnmfWOjtxqEyLkoYXeg2O3wzDOeQ3fjRbd89pGQmQo/+Qn87ncwfjx861vmg6rlIiKDVEqKmXVxuaChAYYNC/WIJBIMyMzL888/T25uLgkJCcybN4/Nmzd3e+3q1atZsGABaWlppKWlUVRU1OP1EaO01G/W5TDjqccs+KZQTy5HTK+jRYvgrbfg5z83F+blweLFClxEZFBS0q6cj6AHL2+++SbFxcWsWLGCbdu2UVhYyMKFC6mqqgp4/caNG7nlllv4y1/+wqZNm8jJyeHqq6/m+PHjAa+PCHY77N3rWdxtJp79TPZ8eAafdmyS9qEcFxGJAkralfMR43IFtxn5vHnzuPjii3nuuecAcDqd5OTkcM8997B06dJz3u9wOEhLS+O5557j1ltvPef19fX1pKamUldXR4rvv4pQsdth2jS/Ropbmc0JRgEwjqPMYFfX+2w2E/BoxkVEBrG2NlNkHCAtDb70pdCOR0KnLz+/gzrz0traytatWykqKvJ+QouFoqIiNm3a1KtnNDU10dbWRnp6erCGGTx2O5SU+AUu1WR4AhcbreSzL/C9v/qVAhcRGfTi4rw9ZhsaQjsWiRxBTditqanB4XCQlZXldz4rK4t9+7r5od3Jgw8+yKhRo/wCIF8tLS20tLR4juvDZd6xUz0XACcxfo0Xp7IHG20BbsYvP0ZEZDBLSYGzZ6G93duvVqQnYb1V+oknnuCNN97gnXfeIcG9ZbiTkpISUlNTPa+cnJwBHmUAGzdCUZFf4AJwiIk0MgSAdGoZw+fmA//rf3m3RIP5NUTbokUkSviuEGj2RXojqDMvGRkZWK1WKisr/c5XVlaSnZ3d471PPfUUTzzxBH/605+YMWNGt9ctW7aM4uJiz3F9fX1oAxi73cy4dCpY0EgSB5kEQAwuCtjlTdJ96SX4059gyxZzfOONWjISkajhrvUCJmm302S9SBdBDV5sNhtz5sxhw4YN3HDDDYBJ2N2wYQN33313t/c9+eSTPPbYY7z33nvMnTu3x88RHx9PfDi1Ii0t7TLjAlDGdJwdE1152EnB59cLh8N0i/7e9wZqlCIiYUMzL9JXQS9SV1xczOLFi5k7dy6XXHIJzz77LI2NjSxZsgSAW2+9ldGjR1NSUgLAypUrWb58OWvXriU3N5eKigoAhg4dytChQ4M93Au3YIHZKeQTwJwkmyoyAUigmYs44H+PlolEJIoNGWIqSTid2i4tvRP0nJebb76Zp556iuXLlzNz5kx27NjB+vXrPUm85eXlnDx50nP9Cy+8QGtrK//jf/wPRo4c6Xk99dRTwR5q/8jLg/feMyn0QDtWypju+fB0yojFZ0np2muhrEzLRCIStSwW0+cI4MwZE8SI9CTodV4GWsjqvNjt3jL+AMuWwVtvsYcpfMYEADKpYh4+1YLj4mDfPgUuIhL1tm0Ddy3SK67wX0qS6NCXn9/qbdQf7HYoKDB7/BISICYGzp6lgaHYMYGJBSfTKfPeExcH//VfClxERDDBijt4aWhQ8CI9C+ut0hGjtNQELmAK0p0962m86OrYUzSJgwyhyXtPcTFceeWAD1VEJBx13nEk0hMFL/1h3DiTpAueXJfPGUMtpirwEBqZyCH/e4YPH8gRioiENfU4kr5Q8HKh7Ha47jqzu8hqhaQk2ohlD1M9lxSwCws+qUVxcaaWi4iIAGbTZcfvftouLeek4KUv7HZYs8b86ea7ZORwQF0de5lCK2YmZhQnGEGN/3OKi5XrIiLSiXvp6OxZdUiRnilht7d8k3KTkmDXLhOAnDrld9kphnGUcQDE0s40dvs/JzERvvWtgRq1iEjESE6G2lrzvqEBIrEfrwwMzbz0lu8MS1OT6Ra9di3cf7/nEhf4NV6czH4S8DaN5MtfVk0XEZFuqNKu9JaCl95asMC/1enLL8M3v+l3yRFyqSMVgBTqGc9h/2c8+qgCFxGRbmjHkfSWgpfeysszS0W33+4951Pfr5l49pHvOZ7Bp97Gi2CSeceODf44RUQilHYcSW8peOmLvDxTOdd3BqbDHqbS3pFCNJZy0jjtf4HDYZaeREQkoLg4U+cTtGwkPVPw0lfuGZgHH/ScqmE4xxkNgI1WprDXe31sR050UpKaL4qInIN79qWtzdT8FAlEwcv5mjIFHnoIJzF+SbpTJrRhs3Q0XkxKMlurb78d1q1TvouIyDko70V6Q1ul+8p3y7TNhp08zmDaoaZxipzP/ua99v774Y47zLVr13q3V4uISECddxxlZoZuLBK+NPPSV6tWebZMn221cICLAIjBRQG7/JN01671316tnBcRkR75zrwo70W6o+ClLzZuhJUrPYe7mY4DKwC5HCGVTnOcl17qTe5VzouIyDkNHep9f+ZM6MYh4U3BS1+88ILnbTUZnCQbMEm6k9nvf21sLPz4x2ap6NVXtWQkItILHS3iAM28SPeU89IbdrtZ8rGaWZbOSbpT2UMc7f73uGvA5OUpaBER6YPkZLPS3t5u+hwlJoZ6RBJuFLyci2+CbofPmEAjQwBIp5YxfN71PnddFwUuIiJ9MnQoVFaa92fOKHiRrrRs1BO73fQw8glczpLAQSYBnZJ0bTb4yU9U10VE5AIpaVfORTMv3Qkw4wKwm2l+SbopNIDFYrZF/+M/mldpqQlcNOsiItJnCl7kXDTz0h3fLtIdqhjBSUYCEE+LN0nX6TS7kAo68mAWL1bgIiJynnx3HCl4kUAUvHRnwQJvkw1Mkm4Z0z3HAZN0VctFROSCxcZ681y0XVoC0bKRL7sd3n4bvvgCTp82SbcduibpHu96v/JcRET6RXKy2Wnk7nHk87ukiIIXD7sdpk0L2AmsicQuSbpd3HknPPCAlotERPrB0KFQVWXeNzQoeBF/WjZyKy3ttoWpb5LueA6bJN3O5s9X4CIi0k+UtCs9UfDi1inHxa2KEVR0VNKNp4WLOBD4/nHjgjk6EZGo4hu8KO9FOlPw4paXB7t3Q36+51TnJN1p7PYm6V57rf/9R48OxChFRKKCdhxJTxS8dHbAO7NyiImeJN3hfMHomJPmA0lJ8L3vqemiiEiQxMV5J8MVvEhnStj1VVpqarbQTZKuy2Uq6a5bB1deaZotqiCdiEhQJCebVMS2Nmhpgfj4UI9IwoWCF18LFpjgpLWV3UzD2TExNZ7DJNOx6Nra6l0iUtNFEZGgSU6G6mrzvqFBwYt4adnIboc1a8yfADfeSGXqRZ4k3QSavZV0wQQ3VVXe60VEJCi040i6E90zL779ixISoK0Nh8NFGVd6LpnKHmLxFqujtdXUc/nBD8yykWZeRESCQkm70p3onnnx7V/U3AwOB58xgSZMIm4GNYzmROB71QpARCSoNPMi3Ynu4GXBAu+OIbom6U6P2dP9vdphJCISVHFx3jwX1XoRX9EdvOTlmaWfm24CoIzpniTdPOwku+q73nPLLfDqq1oyEhEZAO6lo9ZWs+tIBKI95wWgvBzeeYdKMqkkCzBJut1W0v3Wt8w2aRERCbqhQ02vXDCzL2lpoR2PhIfonnnZuBGKinC0ObpU0vVL0vWlSroiIgPGN2lXS0fiFr3Bi90OCxeCw8EhJvol6Y7ipPe6uDhITDTvleciIjKgFLxIING7bFRaCq2tNJLEISYCYMFpKun6amuDxx6DzExV0hURGWAKXiSQ6A1eFiwAq5Uyh3+S7lAa/a9LSoIbb1TQIiISAomJYLGYzi0KXsRtQJaNnn/+eXJzc0lISGDevHls3ry5x+t/85vfkJ+fT0JCAgUFBbz77rv9P6jyciocGVSRCZgk3Ukc9L/m9tu1q0hEJIRiYryzL42NnvZzEuWCHry8+eabFBcXs2LFCrZt20ZhYSELFy6kqqoq4PV///vfueWWW7jtttvYvn07N9xwAzfccANlZWX9Oi7H8y/6JelOp8w/STcpCZYtU+AiIhJi7uDF5fLWFZXoFuNyuVzB/ATz5s3j4osv5rnnngPA6XSSk5PDPffcw9KlS7tcf/PNN9PY2Mgf/vAHz7lLL72UmTNn8uKLL57z89XX15OamkpdXR0pKSmBL7Lb2Zd/AwfbxgEwgmou5WPvxy+5BH79awUuIiJhYP9+ONBRveLiiyE7O7TjkeDo1c/vDkGdeWltbWXr1q0UFRV5P6HFQlFREZs2bQp4z6ZNm/yuB1i4cGG317e0tFBfX+/3OpfGP23is7YcMx6cTKfTrM6sWQpcRETChJJ2pbOgBi81NTU4HA6ysrL8zmdlZVFRURHwnoqKij5dX1JSQmpqqueVk5NzznElfWU+UxMOE0s7E/isa5LuhAnnfIaIiAwM3+ClsbH76yR6RHydl2XLllFXV+d5HTt27Jz3xEzIY/wff8H/F7Oxa5JuXJzZXSQiImFhyBDve828CAR5q3RGRgZWq5XKykq/85WVlWR3s2iZnZ3dp+vj4+OJd3fu6os33iDe1ex/zmaD997TkpGISBiJjYWEBGhuVndpMYI682Kz2ZgzZw4bNmzwnHM6nWzYsIH58+cHvGf+/Pl+1wO8//773V5/3rZv9z8ePx727lXfIhGRMOReOmprM00aJboFfdmouLiY1atXs2bNGvbu3ct3vvMdGhsbWbJkCQC33nory5Yt81x/7733sn79ep5++mn27dvHD37wAz755BPuvvvu/h3Yvff6H//4x5pxEREJU0raFV9Br7B78803U11dzfLly6moqGDmzJmsX7/ek5RbXl6OxeKNoS677DLWrl3Lww8/zPe//30mTZrEb3/7W6ZPn97dpzg/3/iG+fOll+DOO73HIiISdjoHL+npoRuLhF7Q67wMtL7sExcRkchQXQ0ffWTeT5gAU6eGdjzS/8KmzktEsNthzRrzp4iIhCUtG4mv6G3MCCZgKSgw9aaTktTHSEQkTCUkgNUKDoeCF4n2mZfSUm+jjKYmcywiImHHt0FjU5MaNEa76A5eFiwwMy5g/lywILTjERGRbvk2aFSl3egW3ctGeXlmqai01AQuWjISEQlbnfNekpNDNxYJregOXsAELApaRETCnm+bAM28RLfoXjYSEZGIoQaN4qbgRUREIoJmXsRNwYuIiESE2Fhw9+FV8BLdFLyIiEjEcM++NDdDe3toxyKho+BFREQihpaOBBS8iIhIBFHwIqDgRUREIoh2HAkoeBERkQiimRcBBS8iIhJBfIMXNWiMXgpeREQkYlitpsM0aOYlmil4ERGRiOKefWlthba20I5FQkPBi4iIRBTlvYiCFxERiSjacSQKXkREJKIoaVcUvIiISETRspEoeBERkYii4EUUvIiISESxWCAx0bxX8BKdFLyIiEjEcSfttrWZLdMSXRS8iIhIxFHSbnRT8CIiIhFHeS/RTcGLiIhEHAUv0U3Bi4iIRBwVqotuCl5ERCTiJCZCTIx5r5yX6KPgRUREIo7vdummptCORQaeghcREYlI7ryX9nZtl442Cl5ERCQiJSV53yvvJbooeBERkYjku+NIS0fRRcGLiIhEJG2Xjl4KXkREJCL5Lhtp5iW6KHgREZGIpJyX6KXgRUREIlJsLMTHm/eaeYkuCl5ERCRiufNempvB4QjtWGTgKHgREZGIpbyX6BS04KW2tpZFixaRkpLCsGHDuO222zjTQw3n2tpa7rnnHiZPnkxiYiJjx47lu9/9LnV1dcEaooiIRDjtOIpOQQteFi1axO7du3n//ff5wx/+wAcffMC3vvWtbq8/ceIEJ06c4KmnnqKsrIxXX32V9evXc9tttwVriCIiEuE08xKdYlwul6u/H7p3716mTp3Kli1bmDt3LgDr16/n2muv5fPPP2fUqFG9es5vfvMbvvnNb9LY2EhsbGyv7qmvryc1NZW6ujpSUlLO+79BRETC36lT8OGH5n1uLhQUhHQ4cgH68vO7dxFBH23atIlhw4Z5AheAoqIiLBYLH3/8Mf/0T//Uq+e4/wN6ClxaWlpoaWnxuwfM/wQRERnc2tu9My5VVaBv/ZHL/XO7N3MqQQleKioqyMzM9P9EsbGkp6dTUVHRq2fU1NTwox/9qMelJoCSkhIeffTRLudzcnJ6P2AREREJCw0NDaSmpvZ4TZ+Cl6VLl7Jy5coer9m7d29fHhlQfX091113HVOnTuUHP/hBj9cuW7aM4uJiz7HT6aS2tpbhw4cTExPT4+fIycnh2LFjWl4KA/p6hB99TcKLvh7hRV+P/udyuWhoaOhVakmfgpf//b//N//yL//S4zV5eXlkZ2dTVVXld769vZ3a2lqys7N7vL+hoYFrrrmG5ORk3nnnHeLi4nq8Pj4+nnh3laIOw4YN6/EeXykpKfqLF0b09Qg/+pqEF309wou+Hv3rXDMubn0KXkaMGMGIESPOed38+fM5ffo0W7duZc6cOQD8+c9/xul0Mm/evG7vq6+vZ+HChcTHx/P73/+ehISEvgxPREREokBQtkpPmTKFa665hjvuuIPNmzfzt7/9jbvvvpuvf/3rnumg48ePk5+fz+bNmwETuFx99dU0NjbyyiuvUF9fT0VFBRUVFThUNlFEREQ6BCVhF+D111/n7rvv5itf+QoWi4Ubb7yRn/3sZ56Pt7W1sX//fpo60sS3bdvGxx9/DMDEiRP9nnX48GFyc3P7dXzx8fGsWLGiy5KThIa+HuFHX5Pwoq9HeNHXI7SCUudFREREJFjU20hEREQiioIXERERiSgKXkRERCSiKHgRERGRiBK1wcvzzz9Pbm4uCQkJzJs3z7NlWwZWSUkJF198McnJyWRmZnLDDTewf//+UA9LOjzxxBPExMRw3333hXooUe348eN885vfZPjw4SQmJlJQUMAnn3wS6mFFJYfDwSOPPML48eNJTExkwoQJ/OhHP+pVPx7pP1EZvLz55psUFxezYsUKtm3bRmFhIQsXLuxSFViC769//St33XUXH330Ee+//z5tbW2eej8SWlu2bOGll15ixowZoR5KVDt16hSXX345cXFx/PGPf2TPnj08/fTTpKWlhXpoUWnlypW88MILPPfcc+zdu5eVK1fy5JNP8vOf/zzUQ4sqUblVet68eVx88cU899xzgOmHlJOTwz333MPSpUtDPLroVl1dTWZmJn/961/58pe/HOrhRK0zZ84we/ZsfvGLX/DjH/+YmTNn8uyzz4Z6WFFp6dKl/O1vf6O0tDTUQxHgH/7hH8jKyuKVV17xnLvxxhtJTEzk3//930M4sugSdTMvra2tbN26laKiIs85i8VCUVERmzZtCuHIBKCurg6A9PT0EI8kut11111cd911fv9OJDR+//vfM3fuXP7n//yfZGZmMmvWLFavXh3qYUWtyy67jA0bNnDgwAEAdu7cyYcffsjXvva1EI8sugStwm64qqmpweFwkJWV5Xc+KyuLffv2hWhUAmYG7L777uPyyy9n+vTpoR5O1HrjjTfYtm0bW7ZsCfVQBLDb7bzwwgsUFxfz/e9/ny1btvDd734Xm83G4sWLQz28qLN06VLq6+vJz8/HarXicDh47LHHWLRoUaiHFlWiLniR8HXXXXdRVlbGhx9+GOqhRK1jx45x77338v7776sxaphwOp3MnTuXxx9/HIBZs2ZRVlbGiy++qOAlBN566y1ef/111q5dy7Rp09ixYwf33Xcfo0aN0tdjAEVd8JKRkYHVaqWystLvfGVlJdnZ2SEaldx999384Q9/4IMPPmDMmDGhHk7U2rp1K1VVVcyePdtzzuFw8MEHH/Dcc8/R0tKC1WoN4Qijz8iRI5k6darfuSlTpvD222+HaETR7Xvf+x5Lly7l61//OgAFBQUcPXqUkpISBS8DKOpyXmw2G3PmzGHDhg2ec06nkw0bNjB//vwQjiw6uVwu7r77bt555x3+/Oc/M378+FAPKap95StfYdeuXezYscPzmjt3LosWLWLHjh0KXELg8ssv71I+4MCBA4wbNy5EI4puTU1NWCz+PzqtVitOpzNEI4pOUTfzAlBcXMzixYuZO3cul1xyCc8++yyNjY0sWbIk1EOLOnfddRdr167ld7/7HcnJyVRUVACQmppKYmJiiEcXfZKTk7vkGw0ZMoThw4crDylE7r//fi677DIef/xxbrrpJjZv3syqVatYtWpVqIcWla6//noee+wxxo4dy7Rp09i+fTvPPPMM//qv/xrqoUUXV5T6+c9/7ho7dqzLZrO5LrnkEtdHH30U6iFFJSDg61e/+lWohyYdrrjiCte9994b6mFEtf/3//6fa/r06a74+HhXfn6+a9WqVaEeUtSqr6933Xvvva6xY8e6EhISXHl5ea6HHnrI1dLSEuqhRZWorPMiIiIikSvqcl5EREQksil4ERERkYii4EVEREQiioIXERERiSgKXkRERCSiKHgRERGRiKLgRURERCKKghcRERGJKApeREREJKIoeBEREZGIouBFREREIoqCFxEREYko/z+cfPAlxy4oGAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp\n",
    "plt.ion()\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "torch.manual_seed(42)\n",
    "import torch.nn as nn\n",
    "from torch.func import functional_call, grad, vmap, jacrev, jacfwd, hessian\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.optim import Adam, LBFGS\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()\n",
    "import tqdm\n",
    "from tkinter.filedialog import asksaveasfilename\n",
    "\n",
    "g = 9.8\n",
    "mu = 0.3\n",
    "\n",
    "def fun(t, V):\n",
    "    vx, vy = V\n",
    "    drag = mu*np.sqrt(vx**2+vy**2)\n",
    "    return [-drag*vx, -drag*vy-g]\n",
    "\n",
    "V_0 = [30, 10]\n",
    "ts = np.linspace(0, 2, 10000)\n",
    "dt = ts[1]-ts[0]\n",
    "\n",
    "result = solve_ivp(fun, (0, 100), V_0, t_eval=ts)\n",
    "sx = np.cumsum(result.y[0])*dt\n",
    "sy = np.cumsum(result.y[1])*dt\n",
    "\n",
    "ts_train = np.linspace(0, 0.2, 2000)\n",
    "dt_train = ts_train[1]-ts_train[0]\n",
    "result_train = solve_ivp(fun, (0, 100), V_0, t_eval=ts_train)\n",
    "t_train = result_train.t\n",
    "sx_train = np.cumsum(result_train.y[0])*dt_train\n",
    "sy_train = np.cumsum(result_train.y[1])*dt_train\n",
    "\n",
    "noise_x = np.random.normal(0, 0.03, len(t_train))\n",
    "noise_y = np.random.normal(0, 0.02, len(t_train))\n",
    "\n",
    "#sx_train = [x+n for x, n in zip(sx_train, noise_x)]\n",
    "sy_train = [y+n for y, n in zip(sy_train, noise_y)]\n",
    "\n",
    "plt.plot(sx, sy, c='b', alpha=0.3, linewidth=2)\n",
    "plt.scatter(sx_train, sy_train, c='r', s=3)\n",
    "plt.xlim(-0.2, np.max(sx)*1.1)\n",
    "plt.ylim(-0.2, np.max(sy)*1.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.relu = torch.tanh\n",
    "        self.lin_1 = nn.Linear(1, 60)\n",
    "        self.lin_2 = nn.Linear(60, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin_1(x)\n",
    "        x = self.lin_2(self.relu(x))\n",
    "        return x.squeeze()\n",
    "\n",
    "\"\"\" Define dataset.  self.p instance is to specify IVs and BCs \"\"\"\n",
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, time_tensor, pos_tensor):\n",
    "        self.t = time_tensor\n",
    "        self.s = pos_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.t)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.t[idx], self.s[idx]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss: 96.66754\n",
      "Epoch: 2 | Train Loss: 95.29432\n",
      "Epoch: 3 | Train Loss: 93.94885\n",
      "Epoch: 4 | Train Loss: 92.61877\n",
      "Epoch: 5 | Train Loss: 91.35396\n",
      "Epoch: 6 | Train Loss: 90.05218\n",
      "Epoch: 7 | Train Loss: 88.75617\n",
      "Epoch: 8 | Train Loss: 87.41211\n",
      "Epoch: 9 | Train Loss: 86.09309\n",
      "Epoch: 10 | Train Loss: 84.7006\n",
      "Epoch: 11 | Train Loss: 83.19887\n",
      "Epoch: 12 | Train Loss: 81.64662\n",
      "Epoch: 13 | Train Loss: 80.00759\n",
      "Epoch: 14 | Train Loss: 78.14088\n",
      "Epoch: 15 | Train Loss: 76.1525\n",
      "Epoch: 16 | Train Loss: 73.97965\n",
      "Epoch: 17 | Train Loss: 71.63657\n",
      "Epoch: 18 | Train Loss: 69.01489\n",
      "Epoch: 19 | Train Loss: 66.20997\n",
      "Epoch: 20 | Train Loss: 63.21339\n",
      "Epoch: 21 | Train Loss: 60.02269\n",
      "Epoch: 22 | Train Loss: 56.67934\n",
      "Epoch: 23 | Train Loss: 53.22975\n",
      "Epoch: 24 | Train Loss: 49.69266\n",
      "Epoch: 25 | Train Loss: 46.11902\n",
      "Epoch: 26 | Train Loss: 42.47852\n",
      "Epoch: 27 | Train Loss: 38.82055\n",
      "Epoch: 28 | Train Loss: 35.13894\n",
      "Epoch: 29 | Train Loss: 31.44269\n",
      "Epoch: 30 | Train Loss: 27.8205\n",
      "Epoch: 31 | Train Loss: 24.20811\n",
      "Epoch: 32 | Train Loss: 20.73825\n",
      "Epoch: 33 | Train Loss: 17.42374\n",
      "Epoch: 34 | Train Loss: 14.35831\n",
      "Epoch: 35 | Train Loss: 11.48974\n",
      "Epoch: 36 | Train Loss: 8.98495\n",
      "Epoch: 37 | Train Loss: 6.79527\n",
      "Epoch: 38 | Train Loss: 4.97727\n",
      "Epoch: 39 | Train Loss: 3.5456\n",
      "Epoch: 40 | Train Loss: 2.47381\n",
      "Epoch: 41 | Train Loss: 1.73862\n",
      "Epoch: 42 | Train Loss: 1.28449\n",
      "Epoch: 43 | Train Loss: 1.0381\n",
      "Epoch: 44 | Train Loss: 0.92543\n",
      "Epoch: 45 | Train Loss: 0.88442\n",
      "Epoch: 46 | Train Loss: 0.86602\n",
      "Epoch: 47 | Train Loss: 0.8502\n",
      "Epoch: 48 | Train Loss: 0.82806\n",
      "Epoch: 49 | Train Loss: 0.79916\n",
      "Epoch: 50 | Train Loss: 0.7677\n",
      "Epoch: 51 | Train Loss: 0.73651\n",
      "Epoch: 52 | Train Loss: 0.71248\n",
      "Epoch: 53 | Train Loss: 0.69163\n",
      "Epoch: 54 | Train Loss: 0.67594\n",
      "Epoch: 55 | Train Loss: 0.66355\n",
      "Epoch: 56 | Train Loss: 0.65498\n",
      "Epoch: 57 | Train Loss: 0.6445\n",
      "Epoch: 58 | Train Loss: 0.63638\n",
      "Epoch: 59 | Train Loss: 0.63029\n",
      "Epoch: 60 | Train Loss: 0.62094\n",
      "Epoch: 61 | Train Loss: 0.61805\n",
      "Epoch: 62 | Train Loss: 0.61187\n",
      "Epoch: 63 | Train Loss: 0.6074\n",
      "Epoch: 64 | Train Loss: 0.60557\n",
      "Epoch: 65 | Train Loss: 0.60339\n",
      "Epoch: 66 | Train Loss: 0.59976\n",
      "Epoch: 67 | Train Loss: 0.59502\n",
      "Epoch: 68 | Train Loss: 0.59475\n",
      "Epoch: 69 | Train Loss: 0.59382\n",
      "Epoch: 70 | Train Loss: 0.59047\n",
      "Epoch: 71 | Train Loss: 0.58883\n",
      "Epoch: 72 | Train Loss: 0.58866\n",
      "Epoch: 73 | Train Loss: 0.5875\n",
      "Epoch: 74 | Train Loss: 0.58693\n",
      "Epoch: 75 | Train Loss: 0.58556\n",
      "Epoch: 76 | Train Loss: 0.58565\n",
      "Epoch: 77 | Train Loss: 0.58384\n",
      "Epoch: 78 | Train Loss: 0.58485\n",
      "Epoch: 79 | Train Loss: 0.58491\n",
      "Epoch: 80 | Train Loss: 0.58318\n",
      "Epoch: 81 | Train Loss: 0.58299\n",
      "Epoch: 82 | Train Loss: 0.58437\n",
      "Epoch: 83 | Train Loss: 0.58221\n",
      "Epoch: 84 | Train Loss: 0.58216\n",
      "Epoch: 85 | Train Loss: 0.58306\n",
      "Epoch: 86 | Train Loss: 0.58294\n",
      "Epoch: 87 | Train Loss: 0.58297\n",
      "Epoch: 88 | Train Loss: 0.58208\n",
      "Epoch: 89 | Train Loss: 0.58291\n",
      "Epoch: 90 | Train Loss: 0.58237\n",
      "Epoch: 91 | Train Loss: 0.58343\n",
      "Epoch: 92 | Train Loss: 0.58364\n",
      "Epoch: 93 | Train Loss: 0.58305\n",
      "Epoch: 94 | Train Loss: 0.5822\n",
      "Epoch: 95 | Train Loss: 0.58071\n",
      "Epoch: 96 | Train Loss: 0.58151\n",
      "Epoch: 97 | Train Loss: 0.58159\n",
      "Epoch: 98 | Train Loss: 0.57969\n",
      "Epoch: 99 | Train Loss: 0.58352\n",
      "Epoch: 100 | Train Loss: 0.58341\n",
      "Epoch: 101 | Train Loss: 0.58001\n",
      "Epoch: 102 | Train Loss: 0.58321\n",
      "Epoch: 103 | Train Loss: 0.58163\n",
      "Epoch: 104 | Train Loss: 0.58055\n",
      "Epoch: 105 | Train Loss: 0.58002\n",
      "Epoch: 106 | Train Loss: 0.58173\n",
      "Epoch: 107 | Train Loss: 0.58249\n",
      "Epoch: 108 | Train Loss: 0.58006\n",
      "Epoch: 109 | Train Loss: 0.58074\n",
      "Epoch: 110 | Train Loss: 0.58064\n",
      "Epoch: 111 | Train Loss: 0.58174\n",
      "Epoch: 112 | Train Loss: 0.58077\n",
      "Epoch: 113 | Train Loss: 0.58127\n",
      "Epoch: 114 | Train Loss: 0.581\n",
      "Epoch: 115 | Train Loss: 0.58129\n",
      "Epoch: 116 | Train Loss: 0.58082\n",
      "Epoch: 117 | Train Loss: 0.58044\n",
      "Epoch: 118 | Train Loss: 0.58083\n",
      "Epoch: 119 | Train Loss: 0.57964\n",
      "Epoch: 120 | Train Loss: 0.58063\n",
      "Epoch: 121 | Train Loss: 0.57938\n",
      "Epoch: 122 | Train Loss: 0.58073\n",
      "Epoch: 123 | Train Loss: 0.58246\n",
      "Epoch: 124 | Train Loss: 0.58027\n",
      "Epoch: 125 | Train Loss: 0.57792\n",
      "Epoch: 126 | Train Loss: 0.57983\n",
      "Epoch: 127 | Train Loss: 0.58042\n",
      "Epoch: 128 | Train Loss: 0.58131\n",
      "Epoch: 129 | Train Loss: 0.57966\n",
      "Epoch: 130 | Train Loss: 0.57975\n",
      "Epoch: 131 | Train Loss: 0.58138\n",
      "Epoch: 132 | Train Loss: 0.58047\n",
      "Epoch: 133 | Train Loss: 0.58108\n",
      "Epoch: 134 | Train Loss: 0.58007\n",
      "Epoch: 135 | Train Loss: 0.57931\n",
      "Epoch: 136 | Train Loss: 0.57975\n",
      "Epoch: 137 | Train Loss: 0.57984\n",
      "Epoch: 138 | Train Loss: 0.57866\n",
      "Epoch: 139 | Train Loss: 0.57845\n",
      "Epoch: 140 | Train Loss: 0.5788\n",
      "Epoch: 141 | Train Loss: 0.5793\n",
      "Epoch: 142 | Train Loss: 0.57927\n",
      "Epoch: 143 | Train Loss: 0.57971\n",
      "Epoch: 144 | Train Loss: 0.57958\n",
      "Epoch: 145 | Train Loss: 0.57782\n",
      "Epoch: 146 | Train Loss: 0.5784\n",
      "Epoch: 147 | Train Loss: 0.58035\n",
      "Epoch: 148 | Train Loss: 0.57843\n",
      "Epoch: 149 | Train Loss: 0.57934\n",
      "Epoch: 150 | Train Loss: 0.57867\n",
      "Epoch: 151 | Train Loss: 0.57869\n",
      "Epoch: 152 | Train Loss: 0.57893\n",
      "Epoch: 153 | Train Loss: 0.5789\n",
      "Epoch: 154 | Train Loss: 0.5792\n",
      "Epoch: 155 | Train Loss: 0.57803\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [8], line 42\u001b[0m\n\u001b[0;32m     37\u001b[0m scheduler_adam \u001b[38;5;241m=\u001b[39m LambdaLR(optimizer\u001b[38;5;241m=\u001b[39moptimizer_adam,\n\u001b[0;32m     38\u001b[0m                           lr_lambda\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m epoch: \u001b[38;5;241m0.99\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m epoch,\n\u001b[0;32m     39\u001b[0m                           last_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, adam_epochs):\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_t, batch_s \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[0;32m     43\u001b[0m         batch_size \u001b[38;5;241m=\u001b[39m batch_t\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     44\u001b[0m         batch_t\u001b[38;5;241m.\u001b[39mto(DEVICE)\n",
      "File \u001b[1;32md:\\Program Files\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32md:\\Program Files\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32md:\\Program Files\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Program Files\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:277\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Program Files\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:144\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Program Files\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:144\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Program Files\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:121\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    124\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32md:\\Program Files\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:174\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    172\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    173\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_basic_fcn = torch.nn.MSELoss()\n",
    "\n",
    "t_train_tensor = torch.tensor(t_train, dtype=torch.float32)\n",
    "t_train_tensor = t_train_tensor.reshape(len(t_train), -1)\n",
    "s_train_tensor = torch.tensor([[sx, sy] for sx, sy in zip(sx_train, sy_train)], dtype=torch.float32)\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "phys_contrib = 1\n",
    "\n",
    "model = Net().to(DEVICE)\n",
    "\n",
    "train_dataset = MyDataset(t_train_tensor, s_train_tensor)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "\n",
    "loss_best = 1000\n",
    "\n",
    "def phys_loss(inp, out):\n",
    "    out_x = out[:, 0]\n",
    "    out_y = out[:, 1]\n",
    "    grad_outputs = torch.ones_like(out_x)\n",
    "    vx = torch.autograd.grad(out_x, [inp], grad_outputs=grad_outputs, create_graph=True)[0]\n",
    "    vy = torch.autograd.grad(out_y, [inp], grad_outputs=grad_outputs, create_graph=True)[0]\n",
    "    vnorm = torch.sqrt(vx**2+vy**2)\n",
    "    grad_outputs = torch.ones_like(vx)\n",
    "    ax = torch.autograd.grad(vx, [inp], grad_outputs=grad_outputs, create_graph=True)[0]\n",
    "    ay = torch.autograd.grad(vy, [inp], grad_outputs=grad_outputs, create_graph=True)[0]\n",
    "    tmp_loss_vx = -mu*vnorm*vx-ax\n",
    "    tmp_loss_vy = -mu*vnorm*vy-g-ay\n",
    "\n",
    "    return torch.square(tmp_loss_vx) + torch.square(tmp_loss_vy)\n",
    "\n",
    "adam_epochs = 300\n",
    "lbfgs_epochs = 200\n",
    "\n",
    "optimizer_adam = Adam(model.parameters(), lr=0.001)\n",
    "scheduler_adam = LambdaLR(optimizer=optimizer_adam,\n",
    "                          lr_lambda=lambda epoch: 0.99 ** epoch,\n",
    "                          last_epoch=-1)\n",
    "\n",
    "for epoch in range(0, adam_epochs):\n",
    "    for batch_t, batch_s in train_dataloader:\n",
    "        batch_size = batch_t.shape[0]\n",
    "        batch_t.to(DEVICE)\n",
    "        batch_s.to(DEVICE)\n",
    "        model.train()\n",
    "        batch_t = Variable(batch_t, requires_grad=True)\n",
    "        def closure_adam():\n",
    "            optimizer_adam.zero_grad()\n",
    "            loss = loss_basic_fcn(model(batch_t), batch_s) + phys_contrib*torch.sum(phys_loss(batch_t, model(batch_t)))/batch_size\n",
    "            loss.backward()\n",
    "            return loss\n",
    "        optimizer_adam.step(closure_adam)\n",
    "    #scheduler_adam.step()\n",
    "\n",
    "    model.eval()\n",
    "    train_prediction = model(t_train_tensor)\n",
    "    train_loss = loss_basic_fcn(train_prediction, s_train_tensor) + phys_contrib*torch.sum(phys_loss(batch_t, model(batch_t)))/batch_size\n",
    "\n",
    "    print(f\"Epoch: {epoch+1} | Train Loss: {round(float(train_loss), 5)}\")\n",
    "\n",
    "optimizer_lbfgs = LBFGS(model.parameters(), lr=0.002)\n",
    "scheduler_lbfgs = LambdaLR(optimizer=optimizer_lbfgs,\n",
    "                           lr_lambda=lambda epoch: 0.99 ** epoch,\n",
    "                           last_epoch=-1)\n",
    "\n",
    "for epoch in range(0, lbfgs_epochs):\n",
    "    for batch_t, batch_s in train_dataloader:\n",
    "        batch_size = batch_t.shape[0]\n",
    "        batch_t.to(DEVICE)\n",
    "        batch_s.to(DEVICE)\n",
    "        model.train()\n",
    "        batch_t = Variable(batch_t, requires_grad=True)\n",
    "        def closure_lfbgs():\n",
    "            optimizer_lbfgs.zero_grad()\n",
    "            loss = loss_basic_fcn(model(batch_t), batch_s) + phys_contrib*torch.sum(phys_loss(batch_t, model(batch_t)))/batch_size\n",
    "            loss.backward()\n",
    "            return loss\n",
    "        optimizer_lbfgs.step(closure_adam)\n",
    "    #scheduler_lbfgs.step()\n",
    "\n",
    "    model.eval()\n",
    "    train_prediction = model(t_train_tensor)\n",
    "    train_loss = loss_basic_fcn(train_prediction, s_train_tensor) + phys_contrib*torch.sum(phys_loss(batch_t, model(batch_t)))/batch_size\n",
    "\n",
    "    print(f\"Epoch: {epoch+1} | Train Loss: {round(float(train_loss), 5)}\")\n",
    "\n",
    "t_test_tensor = torch.tensor(np.linspace(0, 10, 10000), dtype=torch.float32).reshape(10000, -1)\n",
    "\n",
    "pred_s = model(t_test_tensor).detach().numpy()\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(6,10))\n",
    "\n",
    "axs[0].plot(sx, sy, c='b', alpha=0.3, linewidth=4)\n",
    "axs[0].plot(pred_s[:,0], pred_s[:,1], 'g--')\n",
    "axs[0].scatter(sx_train, sy_train, c='r', s=3)\n",
    "axs[0].set_xlim(0, np.max(sx)*2)\n",
    "axs[0].set_ylim(0, np.max(sy)*2)\n",
    "\n",
    "axs[1].scatter(t_train, sx_train, c='r', s=4)\n",
    "axs[1].plot(np.linspace(0, 10, 10000), pred_s[:,0], 'r--')\n",
    "axs[2].scatter(t_train, sy_train, c='r', s=4)\n",
    "axs[2].plot(np.linspace(0, 10, 10000), pred_s[:,1], 'r--')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
